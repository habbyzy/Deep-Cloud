import pandas as pd 
df = pd.read_csv('gene.csv')
df
import numpy as np
import matplotlib.pyplot as plt
data = df.values
data = data.astype('float32')
data.shape
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from pandas import datetime
import math
import itertools
from sklearn import preprocessing
import datetime
from sklearn.metrics import mean_squared_error
from math import sqrt
result = []
time_steps = 6
for i in range(len(data)-time_steps):
    result.append(data[i:i+time_steps])
result = np.array(result)
train_size = int(0.5*len(result))
train = result[:train_size,:]
x_train = train[:, :-1]
y_train = train[:, -1][:,-1]
x_test = result[train_size:,:-1]
y_test = result[train_size:,-1][:,-1]
feature_nums = len(df.columns)
x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2])
x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2])
print("X_train", x_train.shape)
print("y_train", y_train.shape)
print("X_test", x_test.shape)
print("y_test", y_test.shape)

from __future__ import print_function
import math
#importing keras modules
from keras.models import Sequential
from keras.layers import Dense, Activation ,Dropout , Flatten , Conv1D , MaxPooling1D
from keras.layers.recurrent import LSTM
from keras import losses
from keras import optimizers

def build_model(input):
    model = Sequential()
    model.add(Dense(128,input_shape=(input[0],input[1])))
    model.add(Conv1D(filters=48,kernel_size=1,padding='same',activation='relu',kernel_initializer="glorot_uniform"))
    model.add(MaxPooling1D(pool_size=2,padding='valid'))
    model.add(Conv1D(filters=48,kernel_size=1,padding='same',activation='relu',kernel_initializer="glorot_uniform"))
    model.add(MaxPooling1D(pool_size=2, padding='valid'))
    model.add(LSTM(128,return_sequences=True))
    model.add(LSTM(64,return_sequences=False))
    model.add(Dense(32, activation="relu", kernel_initializer="uniform"))
    model.add(Dense(1, activation="relu", kernel_initializer="uniform"))
    model.compile(loss='mse',optimizer='adam',metrics=['mae'])
    return model

model = build_model([5,1,1])
#Summary of the Model
print(model.summary())

history = model.fit(x_train,
                    y_train,
                    batch_size=128,
                    epochs=100,
                    validation_split=0.2,
                    verbose=2)

#The following is the iterative optimization process for the corresponding case in the manuscript.
Epoch 1/100
1s - loss: 0.0039 - mean_absolute_error: 0.0493 - val_loss: 0.0012 - val_mean_absolute_error: 0.0253
Epoch 2/100
0s - loss: 0.0011 - mean_absolute_error: 0.0253 - val_loss: 0.0012 - val_mean_absolute_error: 0.0256
Epoch 3/100
0s - loss: 0.0011 - mean_absolute_error: 0.0254 - val_loss: 0.0012 - val_mean_absolute_error: 0.0254
Epoch 4/100
0s - loss: 0.0011 - mean_absolute_error: 0.0254 - val_loss: 0.0012 - val_mean_absolute_error: 0.0254
Epoch 5/100
0s - loss: 0.0011 - mean_absolute_error: 0.0253 - val_loss: 0.0012 - val_mean_absolute_error: 0.0255
Epoch 6/100
0s - loss: 0.0011 - mean_absolute_error: 0.0253 - val_loss: 0.0012 - val_mean_absolute_error: 0.0255
Epoch 7/100
0s - loss: 0.0011 - mean_absolute_error: 0.0254 - val_loss: 0.0012 - val_mean_absolute_error: 0.0253
Epoch 8/100
0s - loss: 0.0011 - mean_absolute_error: 0.0253 - val_loss: 0.0012 - val_mean_absolute_error: 0.0254
Epoch 9/100
0s - loss: 0.0011 - mean_absolute_error: 0.0253 - val_loss: 0.0012 - val_mean_absolute_error: 0.0253
Epoch 10/100
0s - loss: 0.0011 - mean_absolute_error: 0.0254 - val_loss: 0.0012 - val_mean_absolute_error: 0.0253
Epoch 11/100
0s - loss: 0.0011 - mean_absolute_error: 0.0255 - val_loss: 0.0012 - val_mean_absolute_error: 0.0252
Epoch 12/100
0s - loss: 0.0011 - mean_absolute_error: 0.0253 - val_loss: 0.0011 - val_mean_absolute_error: 0.0250
Epoch 13/100
0s - loss: 0.0011 - mean_absolute_error: 0.0251 - val_loss: 0.0011 - val_mean_absolute_error: 0.0249
Epoch 14/100
0s - loss: 0.0010 - mean_absolute_error: 0.0247 - val_loss: 0.0010 - val_mean_absolute_error: 0.0243
Epoch 15/100
0s - loss: 0.0010 - mean_absolute_error: 0.0247 - val_loss: 0.0010 - val_mean_absolute_error: 0.0239
Epoch 16/100
0s - loss: 0.0010 - mean_absolute_error: 0.0243 - val_loss: 0.0010 - val_mean_absolute_error: 0.0237
Epoch 17/100
0s - loss: 9.9716e-04 - mean_absolute_error: 0.0241 - val_loss: 9.9542e-04 - val_mean_absolute_error: 0.0234
Epoch 18/100
0s - loss: 9.8797e-04 - mean_absolute_error: 0.0239 - val_loss: 9.9239e-04 - val_mean_absolute_error: 0.0233
Epoch 19/100
0s - loss: 9.7937e-04 - mean_absolute_error: 0.0237 - val_loss: 9.9544e-04 - val_mean_absolute_error: 0.0230
Epoch 20/100
0s - loss: 9.8484e-04 - mean_absolute_error: 0.0237 - val_loss: 9.7972e-04 - val_mean_absolute_error: 0.0230
Epoch 21/100
0s - loss: 9.8150e-04 - mean_absolute_error: 0.0237 - val_loss: 9.8646e-04 - val_mean_absolute_error: 0.0230
Epoch 22/100
0s - loss: 9.7383e-04 - mean_absolute_error: 0.0236 - val_loss: 9.7123e-04 - val_mean_absolute_error: 0.0230
Epoch 23/100
0s - loss: 9.8011e-04 - mean_absolute_error: 0.0237 - val_loss: 9.7673e-04 - val_mean_absolute_error: 0.0232
Epoch 24/100
0s - loss: 9.7810e-04 - mean_absolute_error: 0.0236 - val_loss: 9.7500e-04 - val_mean_absolute_error: 0.0232
Epoch 25/100
0s - loss: 9.8229e-04 - mean_absolute_error: 0.0237 - val_loss: 0.0010 - val_mean_absolute_error: 0.0237
Epoch 26/100
0s - loss: 9.6734e-04 - mean_absolute_error: 0.0235 - val_loss: 9.6735e-04 - val_mean_absolute_error: 0.0230
Epoch 27/100
0s - loss: 9.6640e-04 - mean_absolute_error: 0.0235 - val_loss: 0.0010 - val_mean_absolute_error: 0.0234
Epoch 28/100
0s - loss: 9.6470e-04 - mean_absolute_error: 0.0234 - val_loss: 9.6512e-04 - val_mean_absolute_error: 0.0228
Epoch 29/100
0s - loss: 9.6495e-04 - mean_absolute_error: 0.0234 - val_loss: 9.6296e-04 - val_mean_absolute_error: 0.0229
Epoch 30/100
0s - loss: 9.6900e-04 - mean_absolute_error: 0.0235 - val_loss: 9.6755e-04 - val_mean_absolute_error: 0.0230
Epoch 31/100
0s - loss: 9.6692e-04 - mean_absolute_error: 0.0235 - val_loss: 9.6376e-04 - val_mean_absolute_error: 0.0229
Epoch 32/100
0s - loss: 9.6559e-04 - mean_absolute_error: 0.0234 - val_loss: 9.7067e-04 - val_mean_absolute_error: 0.0228
Epoch 33/100
0s - loss: 9.6704e-04 - mean_absolute_error: 0.0234 - val_loss: 9.6774e-04 - val_mean_absolute_error: 0.0231
Epoch 34/100
0s - loss: 9.6200e-04 - mean_absolute_error: 0.0234 - val_loss: 9.5775e-04 - val_mean_absolute_error: 0.0228
Epoch 35/100
0s - loss: 9.5724e-04 - mean_absolute_error: 0.0233 - val_loss: 9.5619e-04 - val_mean_absolute_error: 0.0227
Epoch 36/100
0s - loss: 9.6711e-04 - mean_absolute_error: 0.0234 - val_loss: 9.6752e-04 - val_mean_absolute_error: 0.0229
Epoch 37/100
0s - loss: 9.6079e-04 - mean_absolute_error: 0.0234 - val_loss: 9.5593e-04 - val_mean_absolute_error: 0.0227
Epoch 38/100
0s - loss: 9.5917e-04 - mean_absolute_error: 0.0233 - val_loss: 9.6753e-04 - val_mean_absolute_error: 0.0228
Epoch 39/100
0s - loss: 9.5919e-04 - mean_absolute_error: 0.0233 - val_loss: 9.6632e-04 - val_mean_absolute_error: 0.0230
Epoch 40/100
0s - loss: 9.5722e-04 - mean_absolute_error: 0.0233 - val_loss: 9.5429e-04 - val_mean_absolute_error: 0.0228
Epoch 41/100
0s - loss: 9.4974e-04 - mean_absolute_error: 0.0232 - val_loss: 9.5494e-04 - val_mean_absolute_error: 0.0226
Epoch 42/100
0s - loss: 9.5131e-04 - mean_absolute_error: 0.0232 - val_loss: 9.5465e-04 - val_mean_absolute_error: 0.0225
Epoch 43/100
0s - loss: 9.4477e-04 - mean_absolute_error: 0.0231 - val_loss: 9.5077e-04 - val_mean_absolute_error: 0.0227
Epoch 44/100
0s - loss: 9.4391e-04 - mean_absolute_error: 0.0230 - val_loss: 9.6711e-04 - val_mean_absolute_error: 0.0231
Epoch 45/100
0s - loss: 9.4658e-04 - mean_absolute_error: 0.0232 - val_loss: 9.5402e-04 - val_mean_absolute_error: 0.0228
Epoch 46/100
0s - loss: 9.3640e-04 - mean_absolute_error: 0.0229 - val_loss: 9.3265e-04 - val_mean_absolute_error: 0.0222
Epoch 47/100
0s - loss: 9.3206e-04 - mean_absolute_error: 0.0228 - val_loss: 9.5694e-04 - val_mean_absolute_error: 0.0222
Epoch 48/100
0s - loss: 9.2854e-04 - mean_absolute_error: 0.0227 - val_loss: 9.3596e-04 - val_mean_absolute_error: 0.0220
Epoch 49/100
0s - loss: 9.3462e-04 - mean_absolute_error: 0.0228 - val_loss: 9.4507e-04 - val_mean_absolute_error: 0.0222
Epoch 50/100
0s - loss: 9.3383e-04 - mean_absolute_error: 0.0228 - val_loss: 9.3383e-04 - val_mean_absolute_error: 0.0223
Epoch 51/100
0s - loss: 9.2924e-04 - mean_absolute_error: 0.0227 - val_loss: 9.4819e-04 - val_mean_absolute_error: 0.0220
Epoch 52/100
0s - loss: 9.2772e-04 - mean_absolute_error: 0.0227 - val_loss: 9.2912e-04 - val_mean_absolute_error: 0.0221
Epoch 53/100
0s - loss: 9.2659e-04 - mean_absolute_error: 0.0226 - val_loss: 9.7797e-04 - val_mean_absolute_error: 0.0233
Epoch 54/100
0s - loss: 9.3880e-04 - mean_absolute_error: 0.0229 - val_loss: 9.3738e-04 - val_mean_absolute_error: 0.0224
Epoch 55/100
0s - loss: 9.2970e-04 - mean_absolute_error: 0.0227 - val_loss: 9.5523e-04 - val_mean_absolute_error: 0.0229
Epoch 56/100
0s - loss: 9.3507e-04 - mean_absolute_error: 0.0228 - val_loss: 9.2422e-04 - val_mean_absolute_error: 0.0218
Epoch 57/100
0s - loss: 9.3379e-04 - mean_absolute_error: 0.0228 - val_loss: 9.5109e-04 - val_mean_absolute_error: 0.0221
Epoch 58/100
0s - loss: 9.3672e-04 - mean_absolute_error: 0.0228 - val_loss: 9.2607e-04 - val_mean_absolute_error: 0.0219
Epoch 59/100
0s - loss: 9.3124e-04 - mean_absolute_error: 0.0227 - val_loss: 9.4722e-04 - val_mean_absolute_error: 0.0223
Epoch 60/100
0s - loss: 9.2785e-04 - mean_absolute_error: 0.0227 - val_loss: 9.2482e-04 - val_mean_absolute_error: 0.0219
Epoch 61/100
0s - loss: 9.3199e-04 - mean_absolute_error: 0.0228 - val_loss: 9.3881e-04 - val_mean_absolute_error: 0.0225
Epoch 62/100
0s - loss: 9.3549e-04 - mean_absolute_error: 0.0228 - val_loss: 9.5880e-04 - val_mean_absolute_error: 0.0222
Epoch 63/100
0s - loss: 9.3684e-04 - mean_absolute_error: 0.0229 - val_loss: 9.4839e-04 - val_mean_absolute_error: 0.0227
Epoch 64/100
0s - loss: 9.2732e-04 - mean_absolute_error: 0.0227 - val_loss: 9.4241e-04 - val_mean_absolute_error: 0.0226
Epoch 65/100
0s - loss: 9.2340e-04 - mean_absolute_error: 0.0226 - val_loss: 9.3242e-04 - val_mean_absolute_error: 0.0219
Epoch 66/100
0s - loss: 9.4061e-04 - mean_absolute_error: 0.0228 - val_loss: 9.1933e-04 - val_mean_absolute_error: 0.0218
Epoch 67/100
0s - loss: 9.3417e-04 - mean_absolute_error: 0.0228 - val_loss: 9.3530e-04 - val_mean_absolute_error: 0.0221
Epoch 68/100
0s - loss: 9.2737e-04 - mean_absolute_error: 0.0226 - val_loss: 9.3128e-04 - val_mean_absolute_error: 0.0223
Epoch 69/100
0s - loss: 9.3488e-04 - mean_absolute_error: 0.0228 - val_loss: 9.2968e-04 - val_mean_absolute_error: 0.0221
Epoch 70/100
0s - loss: 9.2281e-04 - mean_absolute_error: 0.0226 - val_loss: 9.2707e-04 - val_mean_absolute_error: 0.0221
Epoch 71/100
0s - loss: 9.2657e-04 - mean_absolute_error: 0.0226 - val_loss: 9.3575e-04 - val_mean_absolute_error: 0.0220
Epoch 72/100
0s - loss: 9.3403e-04 - mean_absolute_error: 0.0228 - val_loss: 9.2518e-04 - val_mean_absolute_error: 0.0220
Epoch 73/100
0s - loss: 9.2507e-04 - mean_absolute_error: 0.0226 - val_loss: 9.3296e-04 - val_mean_absolute_error: 0.0219
Epoch 74/100
0s - loss: 9.2397e-04 - mean_absolute_error: 0.0226 - val_loss: 9.4393e-04 - val_mean_absolute_error: 0.0226
Epoch 75/100
0s - loss: 9.2932e-04 - mean_absolute_error: 0.0227 - val_loss: 9.3318e-04 - val_mean_absolute_error: 0.0223
Epoch 76/100
0s - loss: 9.2890e-04 - mean_absolute_error: 0.0227 - val_loss: 9.3521e-04 - val_mean_absolute_error: 0.0220
Epoch 77/100
0s - loss: 9.2584e-04 - mean_absolute_error: 0.0227 - val_loss: 9.2610e-04 - val_mean_absolute_error: 0.0219
Epoch 78/100
0s - loss: 9.2876e-04 - mean_absolute_error: 0.0227 - val_loss: 9.7607e-04 - val_mean_absolute_error: 0.0233
Epoch 79/100
0s - loss: 9.2999e-04 - mean_absolute_error: 0.0227 - val_loss: 9.3979e-04 - val_mean_absolute_error: 0.0225
Epoch 80/100
0s - loss: 9.2677e-04 - mean_absolute_error: 0.0227 - val_loss: 9.2855e-04 - val_mean_absolute_error: 0.0222
Epoch 81/100
0s - loss: 9.3216e-04 - mean_absolute_error: 0.0227 - val_loss: 9.3391e-04 - val_mean_absolute_error: 0.0219
Epoch 82/100
0s - loss: 9.2997e-04 - mean_absolute_error: 0.0227 - val_loss: 9.4645e-04 - val_mean_absolute_error: 0.0225
Epoch 83/100
0s - loss: 9.2789e-04 - mean_absolute_error: 0.0227 - val_loss: 9.2410e-04 - val_mean_absolute_error: 0.0221
Epoch 84/100
0s - loss: 9.2853e-04 - mean_absolute_error: 0.0227 - val_loss: 9.2363e-04 - val_mean_absolute_error: 0.0220
Epoch 85/100
0s - loss: 9.2749e-04 - mean_absolute_error: 0.0228 - val_loss: 9.3697e-04 - val_mean_absolute_error: 0.0224
Epoch 86/100
0s - loss: 9.2775e-04 - mean_absolute_error: 0.0227 - val_loss: 9.3042e-04 - val_mean_absolute_error: 0.0221
Epoch 87/100
0s - loss: 9.2944e-04 - mean_absolute_error: 0.0227 - val_loss: 9.5127e-04 - val_mean_absolute_error: 0.0219
Epoch 88/100
0s - loss: 9.3900e-04 - mean_absolute_error: 0.0229 - val_loss: 9.5262e-04 - val_mean_absolute_error: 0.0228
Epoch 89/100
0s - loss: 9.2933e-04 - mean_absolute_error: 0.0227 - val_loss: 9.2125e-04 - val_mean_absolute_error: 0.0218
Epoch 90/100
0s - loss: 9.2377e-04 - mean_absolute_error: 0.0226 - val_loss: 9.4481e-04 - val_mean_absolute_error: 0.0224
Epoch 91/100
0s - loss: 9.2890e-04 - mean_absolute_error: 0.0227 - val_loss: 9.3095e-04 - val_mean_absolute_error: 0.0220
Epoch 92/100
0s - loss: 9.2536e-04 - mean_absolute_error: 0.0226 - val_loss: 9.1874e-04 - val_mean_absolute_error: 0.0217
Epoch 93/100
0s - loss: 9.2222e-04 - mean_absolute_error: 0.0226 - val_loss: 9.4866e-04 - val_mean_absolute_error: 0.0226
Epoch 94/100
0s - loss: 9.2610e-04 - mean_absolute_error: 0.0226 - val_loss: 9.2242e-04 - val_mean_absolute_error: 0.0219
Epoch 95/100
0s - loss: 9.2709e-04 - mean_absolute_error: 0.0227 - val_loss: 9.4733e-04 - val_mean_absolute_error: 0.0226
Epoch 96/100
0s - loss: 9.2746e-04 - mean_absolute_error: 0.0227 - val_loss: 9.3646e-04 - val_mean_absolute_error: 0.0219
Epoch 97/100
0s - loss: 9.2927e-04 - mean_absolute_error: 0.0227 - val_loss: 9.2259e-04 - val_mean_absolute_error: 0.0220
Epoch 98/100
0s - loss: 9.2146e-04 - mean_absolute_error: 0.0225 - val_loss: 9.5431e-04 - val_mean_absolute_error: 0.0223
Epoch 99/100
0s - loss: 9.3559e-04 - mean_absolute_error: 0.0228 - val_loss: 9.7334e-04 - val_mean_absolute_error: 0.0224
Epoch 100/100
0s - loss: 9.3092e-04 - mean_absolute_error: 0.0227 - val_loss: 9.2968e-04 - val_mean_absolute_error: 0.0223

history_dict = history.history
history_dict.keys()

import matplotlib.pyplot as plt

loss_values = history_dict['loss']
val_loss_values = history_dict['val_loss']
loss_values50 = loss_values[0:150]
val_loss_values50 = val_loss_values[0:150]
epochs = range(1, len(loss_values50) + 1)
plt.plot(epochs, loss_values50, 'b',color = 'blue', label='Training loss')
plt.plot(epochs, val_loss_values50, 'b',color='red', label='Validation loss')
plt.rc('font', size = 18)
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.xticks(epochs)
fig = plt.gcf()
fig.set_size_inches(15,7)
plt.show()

mae = history_dict['mean_absolute_error']
vmae = history_dict['val_mean_absolute_error']
epochs = range(1, len(mae) + 1)
plt.plot(epochs, mae, 'b',color = 'blue', label='Training error')
plt.plot(epochs, vmae, 'b',color='red', label='Validation error')
plt.title('Training and validation error')
plt.xlabel('Epochs')
plt.ylabel('Error')
plt.legend()
plt.xticks(epochs)
fig = plt.gcf()
fig.set_size_inches(15,7)
plt.show()

model.metrics_names
trainScore = model.evaluate(x_train, y_train, verbose=0)
testScore = model.evaluate(x_test, y_test, verbose=0)

from sklearn.metrics import mean_absolute_error
print('Trainscore RMSE \tTrain Mean abs Error \tTestscore Rmse \t Test Mean abs Error')
print('%.9f \t\t %.9f \t\t %.9f \t\t %.9f' % (math.sqrt(trainScore[0]),trainScore[1],math.sqrt(testScore[0]),testScore[1]))